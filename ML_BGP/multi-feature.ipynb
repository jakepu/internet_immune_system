{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter Notebook file, we are trying to extract features (month/day/hour/min/sec) from the unix timestamps to do supervised machine training to predict the uptime = ((withdraw time) - (announce time))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score #https://scikit-learn.org/stable/modules/classes.html#regression-metrics\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import OPTICS\n",
    "from plotly.graph_objects import Figure\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import pickle\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime.utcfromtimestamp(start)\n",
    "class record_new:\n",
    "    def __init__(self, init_state, time):\n",
    "        self.last_state = init_state\n",
    "        self.timestamps = []\n",
    "        self.timestamp = float(time)\n",
    "    def update(self, state, time):\n",
    "        if state == 'W' and (self.last_state == 'B' or self.last_state == 'A'):\n",
    "            self.last_state = 'W'\n",
    "            self.timestamps.append([self.timestamp, float(time)])\n",
    "        elif state == 'A' and self.last_state == 'W':\n",
    "            self.last_state = 'A'\n",
    "            self.timestamp = float(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('save.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sorted(data.items(), key = lambda item: len(item[1].timestamps, reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data[0:90000:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('multi_sample.pickle', 'wb') as f:\n",
    "    pickle.dump(sample, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('multi_sample.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a feature preparation pipeline for a model\n",
    "def get_pipeline(model):\n",
    "    pipeline = make_pipeline(\n",
    "        RobustScaler(),\n",
    "        MinMaxScaler(),\n",
    "        model\n",
    "    )\n",
    "    return pipeline\n",
    "# prepare a list of ml models\n",
    "def get_models(models=dict()):\n",
    "    # linear models\n",
    "    models['lr'] = LinearRegression()\n",
    "    models['lasso'] = Lasso()\n",
    "    models['ridge'] = Ridge()\n",
    "    models['en'] = ElasticNet()\n",
    "    models['huber'] = HuberRegressor(max_iter = 10000)\n",
    "    models['lars'] = Lars()\n",
    "    models['llars'] = LassoLars()\n",
    "    models['pa'] = PassiveAggressiveRegressor(max_iter=10000, tol=1e-3)\n",
    "    models['ranscac'] = RANSACRegressor()\n",
    "    models['sgd'] = SGDRegressor(max_iter=10000, tol=1e-3)\n",
    "    models['MLPR'] = MLPRegressor(max_iter = 100000)\n",
    "    models['DBSCAN'] = DBSCAN(min_samples = 20, n_jobs = -1, eps=0.15)\n",
    "    models['forest'] = IsolationForest(n_jobs = -1, max_samples = 1.0)\n",
    "    models['LOF'] = LocalOutlierFactor(n_jobs = -1)\n",
    "    models['OPTICS'] = OPTICS(n_jobs = -1, min_samples=20, cluster_method='dbscan', eps=0.15)\n",
    "    return models\n",
    "# convert history into inputs and outputs\n",
    "def to_supervised(history, n_input):\n",
    "\t# convert history to a univariate series\n",
    "\tX, y = list(), list()\n",
    "\tix_start = 0\n",
    "\t# step over the entire history one time step at a time\n",
    "\tfor i in range(len(history)):\n",
    "\t\t# define the end of the input sequence\n",
    "\t\tix_end = ix_start + n_input\n",
    "\t\t# ensure we have enough data for this instance\n",
    "\t\tif ix_end < len(history):\n",
    "\t\t\tX.append(history[ix_start:ix_end])\n",
    "\t\t\ty.append(history[ix_end])\n",
    "\t\t# move along one time step\n",
    "\t\tix_start += 1\n",
    "\treturn np.asarray(X), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.asarray(data[4][1].timestamps)\n",
    "month = np.zeros((len(input_data),4))\n",
    "for i in range(input_data):\n",
    "    date_obj = input_data[i,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "models = get_models()\n",
    "pipeline = get_pipeline(models['lr'])\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_hat = pipeline.predict(X_test)\n",
    "print('Accuracy score:', r2_score(y_pred=y_hat, y_true = y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.asarray(data[1][1].timestamps)\n",
    "input_data = input_data.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = np.zeros((input_data.shape[0],1))\n",
    "days = np.zeros((input_data.shape[0],1))\n",
    "seconds = np.zeros((input_data.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(month.shape[0]):\n",
    "    date_obj = datetime.utcfromtimestamp(input_data[i,0])\n",
    "    hours[i] = date_obj.hour\n",
    "    days[i] = date_obj.day\n",
    "    seconds[i] = date_obj.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "uptime = input_data[:,1] - input_data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
