{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score #https://scikit-learn.org/stable/modules/classes.html#regression-metrics\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import OPTICS\n",
    "from plotly.graph_objects import Figure\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import pickle\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class record:\n",
    "    def __init__(self, init_state, time):\n",
    "        self.last_state = init_state\n",
    "        self.times = []\n",
    "        self.timestamp = float(time)\n",
    "        self.counter = 0\n",
    "    def update(self, state, time):\n",
    "        if state == 'W' and (self.last_state == 'B' or self.last_state == 'A'):\n",
    "            self.last_state = 'W'\n",
    "            self.times.append(float(time) - self.timestamp)\n",
    "            self.timestamp = float(time)\n",
    "            self.counter += 1\n",
    "        elif state == 'A' and self.last_state == 'W':\n",
    "            self.last_state = 'A'\n",
    "            self.timestamp = float(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('save_sorted.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "data = data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a feature preparation pipeline for a model\n",
    "def get_pipeline(model):\n",
    "    pipeline = make_pipeline(\n",
    "        RobustScaler(),\n",
    "        MinMaxScaler(),\n",
    "        model\n",
    "    )\n",
    "    return pipeline\n",
    "# prepare a list of ml models\n",
    "def get_models(models=dict()):\n",
    "    # linear models\n",
    "    models['lr'] = LinearRegression()\n",
    "    models['lasso'] = Lasso()\n",
    "    models['ridge'] = Ridge()\n",
    "    models['en'] = ElasticNet()\n",
    "    models['huber'] = HuberRegressor(max_iter = 10000)\n",
    "    models['lars'] = Lars()\n",
    "    models['llars'] = LassoLars()\n",
    "    models['pa'] = PassiveAggressiveRegressor(max_iter=10000, tol=1e-3)\n",
    "    models['ranscac'] = RANSACRegressor()\n",
    "    models['sgd'] = SGDRegressor(max_iter=10000, tol=1e-3)\n",
    "    models['MLPR'] = MLPRegressor(max_iter = 100000)\n",
    "    models['DBSCAN'] = DBSCAN(min_samples = 20, n_jobs = -1, eps=0.15)\n",
    "    models['forest'] = IsolationForest(n_jobs = -1, max_samples = 1.0)\n",
    "    models['LOF'] = LocalOutlierFactor(n_jobs = -1)\n",
    "    models['OPTICS'] = OPTICS(n_jobs = -1, min_samples=20, cluster_method='dbscan', eps=0.15)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0: 2\n",
      "sample 1: 1\n",
      "sample 2: 2\n",
      "sample 3: 2\n",
      "sample 4: 2\n",
      "sample 5: 3\n",
      "sample 6: 1\n",
      "sample 7: 2\n",
      "sample 8: 3\n",
      "sample 9: 2\n",
      "sample 10: 2\n",
      "sample 11: 2\n",
      "sample 12: 2\n",
      "sample 13: 2\n",
      "sample 14: 2\n",
      "sample 15: 2\n",
      "sample 16: 2\n",
      "sample 17: 2\n",
      "sample 18: 2\n",
      "sample 19: 2\n",
      "sample 20: 2\n",
      "sample 21: 2\n",
      "sample 22: 2\n",
      "sample 23: 2\n",
      "sample 24: 2\n",
      "sample 25: 2\n",
      "sample 26: 2\n",
      "sample 27: 2\n",
      "sample 28: 2\n",
      "sample 29: 2\n",
      "sample 30: 2\n",
      "sample 31: 2\n",
      "sample 32: 2\n",
      "sample 33: 2\n",
      "sample 34: 2\n",
      "sample 35: 2\n",
      "sample 36: 2\n",
      "sample 37: 2\n",
      "sample 38: 2\n",
      "sample 39: 2\n",
      "sample 40: 2\n",
      "sample 41: 2\n",
      "sample 42: 1\n",
      "sample 43: 1\n",
      "sample 44: 2\n",
      "sample 45: 2\n",
      "sample 46: 2\n",
      "sample 47: 2\n",
      "sample 48: 2\n",
      "sample 49: 2\n",
      "sample 50: 2\n",
      "sample 51: 2\n",
      "sample 52: 2\n",
      "sample 53: 2\n",
      "sample 54: 2\n",
      "sample 55: 1\n",
      "sample 56: 2\n",
      "sample 57: 2\n",
      "sample 58: 2\n",
      "sample 59: 2\n",
      "sample 60: 2\n",
      "sample 61: 3\n",
      "sample 62: 2\n",
      "sample 63: 2\n",
      "sample 64: 4\n",
      "sample 65: 2\n",
      "sample 66: 2\n",
      "sample 67: 2\n",
      "sample 68: 2\n",
      "sample 69: 2\n",
      "sample 70: 2\n",
      "sample 71: 2\n",
      "sample 72: 2\n",
      "sample 73: 2\n",
      "sample 74: 2\n",
      "sample 75: 2\n",
      "sample 76: 2\n",
      "sample 77: 2\n",
      "sample 78: 2\n",
      "sample 79: 2\n",
      "sample 80: 2\n",
      "sample 81: 2\n",
      "sample 82: 2\n",
      "sample 83: 2\n",
      "sample 84: 2\n",
      "sample 85: 2\n",
      "sample 86: 2\n",
      "sample 87: 2\n",
      "sample 88: 2\n",
      "sample 89: 1\n",
      "sample 90: 2\n",
      "sample 91: 3\n",
      "sample 92: 2\n",
      "sample 93: 3\n",
      "sample 94: 2\n",
      "sample 95: 2\n",
      "sample 96: 1\n",
      "sample 97: 2\n",
      "sample 98: 2\n",
      "sample 99: 2\n",
      "sample 100: 2\n",
      "sample 101: 2\n",
      "sample 102: 1\n",
      "sample 103: 2\n",
      "sample 104: 2\n",
      "sample 105: 1\n",
      "sample 106: 1\n",
      "sample 107: 1\n",
      "sample 108: 2\n",
      "sample 109: 1\n",
      "sample 110: 2\n",
      "sample 111: 2\n",
      "sample 112: 1\n",
      "sample 113: 2\n",
      "sample 114: 2\n",
      "sample 115: 2\n",
      "sample 116: 2\n",
      "sample 117: 2\n",
      "sample 118: 2\n",
      "sample 119: 1\n",
      "sample 120: 2\n",
      "sample 121: 1\n",
      "sample 122: 2\n",
      "sample 123: 2\n",
      "sample 124: 1\n",
      "sample 125: 1\n",
      "sample 126: 2\n",
      "sample 127: 2\n",
      "sample 128: 1\n",
      "sample 129: 2\n",
      "sample 130: 1\n",
      "sample 131: 2\n",
      "sample 132: 1\n",
      "sample 133: 2\n",
      "sample 134: 2\n",
      "sample 135: 1\n",
      "sample 136: 1\n",
      "sample 137: 1\n",
      "sample 138: 1\n",
      "sample 139: 1\n",
      "sample 140: 2\n",
      "sample 141: 1\n",
      "sample 142: 1\n",
      "sample 143: 2\n",
      "sample 144: 1\n",
      "sample 145: 2\n",
      "sample 146: 2\n",
      "sample 147: 1\n",
      "sample 148: 1\n",
      "sample 149: 1\n",
      "sample 150: 2\n",
      "sample 151: 2\n",
      "sample 152: 1\n",
      "sample 153: 1\n",
      "sample 154: 1\n",
      "sample 155: 1\n",
      "sample 156: 1\n",
      "sample 157: 1\n",
      "sample 158: 1\n",
      "sample 159: 1\n",
      "sample 160: 1\n",
      "sample 161: 1\n",
      "sample 162: 1\n",
      "sample 163: 1\n",
      "sample 164: 1\n",
      "sample 165: 1\n",
      "sample 166: 1\n",
      "sample 167: 1\n",
      "sample 168: 1\n",
      "sample 169: 1\n",
      "sample 170: 1\n",
      "sample 171: 1\n",
      "sample 172: 2\n",
      "sample 173: 1\n",
      "sample 174: 1\n",
      "sample 175: 1\n",
      "sample 176: 1\n",
      "sample 177: 1\n",
      "sample 178: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = get_models()\n",
    "counter = 0\n",
    "for each_pair in data:\n",
    "    df = pd.DataFrame({'Uptime':each_pair[1].times})\n",
    "    input_data_reshaped = df['Uptime'].values.reshape(-1, 1)\n",
    "    pipeline = make_pipeline(RobustScaler(), models['LOF'])\n",
    "    df['Outlier'] = pipeline.fit_predict(input_data_reshaped)\n",
    "    outliers = df[df['Outlier'] == -1]\n",
    "    inliners = df[df['Outlier'] == 1].copy()\n",
    "    input_data_reshaped = inliners['Uptime'].values.reshape(-1, 1)\n",
    "    pipeline = get_pipeline(models['DBSCAN'])\n",
    "    inliners['result'] = pipeline.fit_predict(input_data_reshaped)\n",
    "    print('sample %d:'%counter, len(set(inliners['result'].values)))\n",
    "    for i in set(inliners['result'].values):\n",
    "        plt.scatter(x=inliners[inliners['result'] == i].index, y=inliners[inliners['result'] == i]['Uptime'])\n",
    "    plt.savefig('./figs/%d.png'%counter, format = 'png')\n",
    "    plt.clf()\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4757\n"
     ]
    }
   ],
   "source": [
    "print(data[0][1].counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
